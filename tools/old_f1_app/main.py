import json
import dash
from dash import html, dcc, dash_table, no_update
from dash.dependencies import Input, Output, State
from plotly import graph_objects as go
import pandas as pd
import requests
import numpy as np
import os
from dash.exceptions import PreventUpdate
from datetime import datetime, timedelta
import dash_bootstrap_components as dbc
from urllib.parse import unquote
import dash_mantine_components as dmc
from functions import plot_track_map, process_drivers_data, process_race_control_data, process_weather_data, process_positions_data, process_laps_data, plot_live_map, plot_telemetry, interpolate_points, rotate
import dash_daq as daq
import joblib
from joblib import Memory
from line_profiler_pycharm import profile
import time

# Initialize Dash app
app = dash.Dash(__name__, suppress_callback_exceptions=True, external_stylesheets=[dbc.themes.BOOTSTRAP], title='F1 Buddy', meta_tags=[{'name': 'viewport', 'content': 'width=device-width, initial-scale=1.0'}])
server = app.server
current_dir = os.path.dirname(os.path.abspath(__file__))

# Create a memory object for caching
cachedir = './joblib_cache'  # Define your cache directory
memory = Memory(cachedir, verbose=0)

# Fetch meetings data
meetings = requests.get('https://api.openf1.org/v1/meetings')
meetings_dict = meetings.json()
meetings_df = pd.DataFrame(meetings_dict)
# Group meetings by year
grouped_meetings = meetings_df.groupby('year')

# Create an AccordionItem for each year
accordion_items = []
for year, group in grouped_meetings:
    # Create a Card for each meeting in the year
    cards = []
    for _, row in group.iterrows():
        meeting_key = row['meeting_key']

        # Define the path to the cache file
        cache_file_path = os.path.join('cache', 'session', f'{meeting_key}.json')

        # Check if the session data is in the cache
        if os.path.exists(cache_file_path):
            # If the cache file exists, load the session data from it
            with open(cache_file_path, 'r') as cache_file:
                sessions_data = json.load(cache_file)
        else:
            # If the cache file doesn't exist, fetch the data and save it to the cache
            sessions_response = requests.get(f'https://api.openf1.org/v1/sessions?meeting_key={meeting_key}')
            sessions_data = sessions_response.json()

            # Save the session data to the cache
            with open(cache_file_path, 'w') as cache_file:
                json.dump(sessions_data, cache_file)

            # Sleep for a third of a second to limit to 3 requests per second
            time.sleep(1 / 3)

        sessions_df = pd.DataFrame(sessions_data)
        session_buttons = []
        for _, session_row in sessions_df.iterrows():
            session_name = session_row['session_name']
            session_name_formatted = session_name.replace(' ', '_')
            session_start_time = session_row['date_start'].rsplit('+', 1)[0]  # Assuming 'date_start' is the column name for session start time
            session_start_time = datetime.strptime(session_start_time, "%Y-%m-%dT%H:%M:%S")
            session_start_time = session_start_time.strftime("%H:%M")  # Format the start time as HH:MM
            session_button = dcc.Link(
                dmc.Button(
                    f"{session_name} (Starts at {session_start_time})",  # Append the start time to the session name
                    variant="light",
                    color="blue",
                    fullWidth=True,
                    mt="md",
                    radius="md",
                ),
                href=f'/{meeting_key}/{session_name_formatted}'  # Set the URL to the details page for the session
            )
            session_buttons.append(session_button)

        start_date = row['date_start']
        # print('start date is')
        # print(start_date)
        start_date = row['date_start'].rsplit('+', 1)[0]
        start_date = datetime.strptime(start_date, "%Y-%m-%dT%H:%M:%S")
        start_date = start_date.strftime("%b %d, %Y")

        circuit = row['circuit_short_name']

        # Try to load the track and circuit info data
        try:
            pos_filename = os.path.join('Circuits', 'Tracks', f'2023_{circuit}_track.csv')
            pos = pd.read_csv(pos_filename)
            circuit_info_filename = os.path.join('Circuits', 'Corners', f'2023_{circuit}_corners.csv')
            circuit_info = pd.read_csv(circuit_info_filename)

            # Generate the track map
            fig = plot_track_map(pos, circuit_info, circuit)

            # Create the Card with the desired layout
            card_content = dcc.Graph(
                id='track-map',
                figure=fig,  # The Plotly figure generated by the plot_track_map function
                config={'displayModeBar': False, 'staticPlot': True},  # Optional: hide the mode bar
                style={"width": "100%", "height": "200px"}  # Optional: set the width and height
            )
        except FileNotFoundError:
            # If the track map file is not found, use the chequered flag image
            card_content = dmc.Image(
                src="/assets/chequered_flag.png",  # Path to the chequered flag image
                alt="Chequered flag",
                style={"width": "100%", "height": "auto"}
            )

        card = dmc.Card(
            children=[
                dmc.CardSection(card_content),
                dmc.Group(
                    [
                        dmc.Text(row['meeting_name'], weight=500),
                        dmc.Badge(start_date, color="red", variant="light"),
                    ],
                    position="apart",
                    mt="md",
                    mb="xs",
                ),
                *session_buttons,
            ],
            withBorder=True,
            shadow="sm",
            radius="md",
            style={"width": 350, "flex": "1 1 auto"},  # Add flex property
        )

        # Wrap the Card in a dbc.Col for layout
        card_col = dbc.Col(card, style={"padding": "10px"})  # Add padding for spacing between cards
        cards.append(card_col)

    # Wrap the cards in a dbc.Row for layout
    cards_row = dbc.Row(cards, style={"display": "flex", "flexWrap": "wrap"})  # Add display and flexWrap properties

    # Create an AccordionItem for the year
    accordion_item = dmc.AccordionItem(
        [
            dmc.AccordionControl(str(year)),
            dmc.AccordionPanel(cards_row)
        ],
        value=str(year)
    )
    accordion_items.append(accordion_item)

# Create the Accordion with all items
# Set all years except 2023 as expanded by default
default_active_keys = [str(year) for year in grouped_meetings.groups.keys() if year != 2023]
accordion = dmc.Accordion(children=accordion_items, value=default_active_keys)

# Set the Accordion as the home layout
home_layout = dbc.Container([
    html.H1('Grand Prix List'),
    html.Div(accordion, style={'width': '80%'})  # Wrap the Accordion in a Div and control the width using CSS
], fluid=True)

last_update_timestamps = {
    'weather': datetime.min.isoformat(),
    'drivers': datetime.min.isoformat(),
    'laps': datetime.min.isoformat(),
    'race_control': datetime.min.isoformat(),
    'positions': datetime.min.isoformat(),
}


@profile
def generate_session_details_layout(meeting_key, session_name):
    selected_meeting_df = meetings_df[meetings_df['meeting_key'] == int(meeting_key)]
    meeting_key = selected_meeting_df['meeting_key'].iloc[0]
    meeting_name = selected_meeting_df['meeting_name'].iloc[0]

    # Define the path to the cache file
    cache_file_path = os.path.join('cache', 'session', f'{meeting_key}.json')

    # Check if the session data is in the cache
    if os.path.exists(cache_file_path):
        # If the cache file exists, load the session data from it
        with open(cache_file_path, 'r') as cache_file:
            sessions_data = json.load(cache_file)
    else:
        # If the cache file doesn't exist, fetch the data and save it to the cache
        sessions_response = requests.get(f'https://api.openf1.org/v1/sessions?meeting_key={meeting_key}')
        sessions_data = sessions_response.json()

        # Save the session data to the cache
        with open(cache_file_path, 'w') as cache_file:
            json.dump(sessions_data, cache_file)

    sessions_df = pd.DataFrame(sessions_data)
    selected_session_df = sessions_df[sessions_df['session_name'] == session_name]
    session_key = selected_session_df['session_key'].iloc[0]
    store_session_key = dcc.Store(id='session-key-store', data=session_key)

    drivers_response = fetch_data(f'https://api.openf1.org/v1/drivers?session_key={session_key}')
    last_update_timestamps["drivers"] = datetime.now().isoformat(timespec='milliseconds')
    drivers_data = drivers_response.json()
    drivers_df, drivers_columns = process_drivers_data(drivers_data)
    drivers_dict = drivers_df.to_dict('records')
    drivers_data_store = dcc.Store(id='drivers-store', data={'drivers_data': drivers_dict, 'drivers_columns': drivers_columns})


    # Fetch race control events for the session
    race_control_response = fetch_data(
        f'https://api.openf1.org/v1/race_control?session_key={session_key}')  # Assuming session_key is the same as meeting_key for demonstration
    last_update_timestamps["race_control"] = datetime.now().isoformat(timespec='milliseconds')
    race_control_data = race_control_response.json()
    race_control_df = process_race_control_data(race_control_data)
    race_control_dict = race_control_df.to_dict('records')
    race_control_data_store = dcc.Store(id='race-control-store', data=race_control_dict)


    meeting_name_formatted = meeting_name.replace(' ', '_')

    session_weather_response = fetch_data(f'https://api.openf1.org/v1/weather?session_key={session_key}')
    last_update_timestamps["weather"] = datetime.now().isoformat(timespec='milliseconds')
    weather_data = session_weather_response.json()
    weather_df= process_weather_data(weather_data)
    # print(weather_df['date'].dtype)
    # print(race_control_df['date'].dtype)
    # print(weather_df['date'].head())
    # print(race_control_df['date'].head())
    # For weather_df
    weather_df['date'] = pd.to_datetime(weather_df['date'], format='ISO8601')

    # For race_control_df, we need to add a date and fix the timezone information
    def fix_race_control_date(date_str):
        # Add a placeholder date (we'll use the date from weather_df later)
        date_str = '2024-03-24T' + date_str
        # Fix the timezone information
        if date_str.endswith('+00:'):
            date_str = date_str[:-1] + '00'
        return date_str

    race_control_df['date'] = race_control_df['date'].apply(fix_race_control_date)
    race_control_df['date'] = pd.to_datetime(race_control_df['date'], format='%Y-%m-%dT%H:%M:%S%z')

    # Now, replace the placeholder date in race_control_df with the actual date from weather_df
    actual_date = weather_df['date'].dt.date.iloc[0]
    race_control_df['date'] = race_control_df['date'].apply(
        lambda x: x.replace(year=actual_date.year, month=actual_date.month, day=actual_date.day))

    # Now you can create the date range
    weather_timestamps = pd.date_range(start=weather_df['date'].min(), end=race_control_df['date'].max(), freq='15min')
    # print("Weather timestamps:")
    # print(weather_timestamps)
    unix_weather_timestamps = weather_timestamps.astype('int64') / 10 ** 9
    slider_labels = {str(unix_timestamp): timestamp.strftime('%H:%M') for unix_timestamp, timestamp in
                     zip(unix_weather_timestamps, weather_timestamps)}
    slider_labels[race_control_df['timestamp'].max()] = "Live"
    weather_df_dict = weather_df.to_dict('records')
    slider_labels_dict = {str(key): str(value) for key, value in slider_labels.items()}
    weather_data_store = dcc.Store(id='weather-store', data={'weather_data': weather_df_dict, 'slider_labels': slider_labels_dict})


    # Generate the weather plots
    initial_weather_plots = generate_weather_plots(weather_df)
    weather_plots_placeholder = html.Div(id='weather-plots')

    year = selected_meeting_df['year'].iloc[0]
    circuit = selected_meeting_df['circuit_short_name'].iloc[0]

    laps_response = fetch_data(f'https://api.openf1.org/v1/laps?session_key={session_key}')
    last_update_timestamps["laps"] = datetime.now().isoformat(timespec='milliseconds')
    laps_data = laps_response.json()
    all_laps_df = pd.DataFrame(laps_data)
    laps_df, fastest_laps_df, all_laps_df = process_laps_data(laps_data, drivers_df)
    laps_df_dict = laps_df.to_dict('records')
    fastest_laps_df_dict = fastest_laps_df.to_dict('records')
    laps_data_store = dcc.Store(id='laps-store', data={'laps_data': laps_df_dict, 'fastest_laps_data': fastest_laps_df_dict})

    print("Initial last update timestamps:", last_update_timestamps)

    positions_response = fetch_data(f'https://api.openf1.org/v1/position?session_key={session_key}')
    last_update_timestamps['positions'] = datetime.now().isoformat(timespec='milliseconds')
    positions_data = positions_response.json()
    positions_df = process_positions_data(positions_data)
    positions_df_dict = positions_df.to_dict('records')
    positions_data_store = dcc.Store(id='positions-store', data=positions_df_dict)
    initial_positions_over_time_plot = plot_driver_positions_over_time(positions_df, all_laps_df)

    pos_filename = os.path.join(current_dir, 'Circuits', 'Tracks', f'2023_{circuit}_track.csv')
    pos = pd.read_csv(pos_filename)
    # print(pos)
    # session.load()
    # circuit_info = session.get_circuit_info()
    circuit_info_filename = os.path.join(current_dir, 'Circuits', 'Corners', f'2023_{circuit}_corners.csv')
    circuit_info = pd.read_csv(circuit_info_filename)
    # print(circuit_info)


    telemetry_laps_df = laps_df
    telemetry_laps_data = telemetry_laps_df.to_dict('records')
    telemetry_laps_store = dcc.Store(id='telemetry-laps-store', data=telemetry_laps_data)
    # Conversion of 'date_start' to timedelta (assuming the format is HH:MM:SS.sss)
    telemetry_laps_df['date_start'] = pd.to_timedelta(telemetry_laps_df['date_start'])
    # Conversion of 'lap_duration' to timedelta (adding "00:" to ensure it's hours:minutes:seconds.milliseconds format)
    telemetry_laps_df['lap_duration'] = pd.to_timedelta("00:" + telemetry_laps_df['lap_duration'])
    # The reference start of the day for calculating datetime from timedelta
    # Extract the date from the DataFrame
    session_date_str = selected_session_df['date_start'].iloc[0]  # Assuming 'date_start' is the column name for session start time
    # Convert the date string to a datetime object
    session_date = pd.to_datetime(session_date_str)
    # Use the session date as the reference date for calculating datetime from timedelta
    reference_date = session_date.date()
    reference_date = datetime.combine(reference_date, datetime.min.time())

    # Calculation of start and end times
    driver_number = telemetry_laps_df['driver_number'].iloc[0]
    driver_lap_start_td = telemetry_laps_df[telemetry_laps_df['driver_number'] == driver_number]['date_start'].iloc[0]
    driver_lap_end_td = driver_lap_start_td + telemetry_laps_df[telemetry_laps_df['driver_number'] == driver_number]['lap_duration'].iloc[0]
    # Converting timedeltas to datetimes by adding them to a reference date
    driver_lap_start_datetime = reference_date + driver_lap_start_td
    driver_lap_end_datetime = reference_date + driver_lap_end_td
    # Formatting the datetime objects to strings
    driver_lap_start = driver_lap_start_datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]
    driver_lap_end = driver_lap_end_datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]
    # print(driver_lap_start)
    # print(driver_lap_end)
    locations_response = fetch_data(f'https://api.openf1.org/v1/location?session_key={session_key}&driver_number={driver_number}&date>={driver_lap_start}&date<={driver_lap_end}')
    car_data_response = fetch_data(f'https://api.openf1.org/v1/car_data?driver_number={driver_number}&session_key={session_key}&date>={driver_lap_start}&date<={driver_lap_end}')
    locations_data = locations_response.json()
    car_data = car_data_response.json()
    car_data_df = pd.DataFrame(car_data)
    for i, date_str in enumerate(car_data_df['date']):
        if date_str is not None and len(date_str) == 19:  # Length 19 indicates no fractional seconds
            date_str += ".000000"
            car_data_df.loc[i, 'date'] = date_str
    car_data_original_df = car_data_df.copy()
    # print(len(car_data_df))
    locations_df = pd.DataFrame(locations_data)
    for i, date_str in enumerate(locations_df['date']):
        if date_str is not None and len(date_str) == 19:  # Length 19 indicates no fractional seconds
            date_str += ".000000"
            locations_df.loc[i, 'date'] = date_str
    # print(len(locations_df))
    locations_df['date'] = pd.to_datetime(locations_df['date'])
    # print(car_data_df['date'].iloc[0])
    car_data_df['date'] = pd.to_datetime(car_data_df['date'])
    locations_df = pd.merge_asof(
        locations_df,
        car_data_df,
        on='date',
        tolerance=pd.Timedelta('500ms')
    )
    locations_df = locations_df.dropna(subset=['rpm'])
    # print("length of new toleranced car data/location merge at 1ms")
    # print(len(locations_df))


    stints_response = fetch_data(f'https://api.openf1.org/v1/stints?session_key={session_key}')
    stints_data = stints_response.json()
    stints_df = pd.DataFrame(stints_data)
    stints_df_dict = stints_df.to_dict('records')
    stints_data_store = dcc.Store(id='stints-store', data=stints_df_dict)

    pits_response = fetch_data(f'https://api.openf1.org/v1/pit?session_key={session_key}')
    pits_data = pits_response.json()
    pits_df = pd.DataFrame(pits_data)
    pits_df_dict = pits_df.to_dict('records')
    pits_data_store = dcc.Store(id='pits-store', data=pits_df_dict)

    stints_plot = plot_driver_stints(stints_df, pits_df)

    track_map, latest_locations_df = plot_live_map(pos, circuit_info, circuit, locations_df)
    # fig = plot_track_map(pos, circuit_info, circuit)

    initial_telemetry_plots = plot_telemetry(circuit_info, latest_locations_df)
    telemetry_plots_placeholder = html.Div(id='telemetry-plots')

    # Flag colors mapping
    flag_colors = {
        None: 'slategray',
        'GREEN': 'green',
        'DOUBLE YELLOW': 'yellow',
        'CLEAR': 'white',
        'YELLOW': 'yellow',
        'RED': 'red',
        'BLUE': 'dodgerblue',
        'CHEQUERED': 'black',
        'BLACK AND WHITE': 'black'  # Use black for 'BLACK AND WHITE'
    }

    overlap_threshold = 1  # Threshold for overlap detection, adjust as needed
    bottom_offset_base = -10  # Fixed offset from the bottom for the bottom-most markers
    # Initialize a new list and dictionary for storing marker properties and position stack heights
    markers = []
    position_stack_heights = {}

    for i, (timestamp, flag, message) in enumerate(
            zip(race_control_df['timestamp'], race_control_df['flag'], race_control_df['message'])):
        # Calculate left position based on timestamp
        left_position = (timestamp - min(min(weather_df['timestamp']), min(race_control_df['timestamp']))) / (
                max(max(weather_df['timestamp']), max(race_control_df['timestamp'])) - min(min(weather_df['timestamp']),
                                                                                           min(race_control_df[
                                                                                                   'timestamp']))) * 100

        # Determine if there's overlap and calculate bottom position
        overlap = False
        bottom_offset = bottom_offset_base  # Start with base offset for bottom-most markers
        for pos, height in position_stack_heights.items():
            if abs(left_position - pos) < overlap_threshold:
                overlap = True
                position_stack_heights[pos] += 1
                bottom_offset += position_stack_heights[pos] * 25 -27.5 # Increment for overlapping markers
                break

        if not overlap:
            position_stack_heights[left_position] = 1  # Initialize with a base stack height for non-overlapping markers

        timestamp_datetime = datetime.fromtimestamp(timestamp) if isinstance(timestamp, (float, int)) else timestamp
        # Convert timestamp to readable format, assuming timestamp_datetime is defined
        formatted_timestamp = timestamp_datetime.strftime('%Y-%m-%d %H:%M:%S')

        # Create marker element with `bottom` style instead of `top`
        marker_id = f'marker-{i}'
        marker = html.Span('●', id=marker_id, style={
            'position': 'absolute',
            'left': f'{left_position}%',
            'bottom': f'{bottom_offset}px',
            'color': flag_colors[flag],
            'font-size': '25px',
            'text-shadow': '0 0 2px #000',
            'cursor': 'default',
        })

        # Tooltip remains unchanged
        tooltip_message = f'{formatted_timestamp}: {message}'
        tooltip = dbc.Tooltip(tooltip_message, target=marker_id)

        markers.append((marker, tooltip))

    # The container `div` might not need a dynamic height in this approach since we're positioning from the bottom
    markers_div = html.Div([marker for marker_tuple in markers for marker in marker_tuple], style={
        'position': 'relative',
        'min-height': '75px'  # Set a minimum height, but this can be adjusted as needed
    })

    if selected_session_df.empty:
        return html.Div([
            html.H2("Session not found."),
            html.A('Back to Meeting Details', href=f'/meeting_details/{meeting_key}'),
        ])

    # Generate the Dash DataTable for the session details
    session_details_table = dash_table.DataTable(
        columns=[
            {'name': i, 'id': i} for i in selected_session_df.columns
        ],
        data=selected_session_df.to_dict('records'),
        style_cell={'textAlign': 'left', 'border': '1px #1e1f22'},
        style_header={
            'backgroundColor': 'rgb(30, 30, 30)',
            'color': '#c9c9c9'
        },
        style_data={
            'backgroundColor': '#2b2d30',
            'color': '#c9c9c9'
        },
    )

    # Define the columns with user-friendly display names
    lap_table_columns = [
        {'name': 'Lap #', 'id': 'lap_number'},
        {'name': '#', 'id': 'driver_number'},
        {'name': 'Full Name', 'id': 'full_name'},
        {'name': 'Team Name', 'id': 'team_name'},
        # Add more columns with logical names as needed
        {'name': 'Start Time', 'id': 'date_start'},
        {'name': 'Lap Time', 'id': 'lap_duration'},
        {'name': 'Sector 1', 'id': 'duration_sector_1'},
        {'name': 'Sector 2', 'id': 'duration_sector_2'},
        {'name': 'Sector 3', 'id': 'duration_sector_3'},
        # Assuming segments were dropped as per the previous operation, omit them or adjust accordingly
    ]

    fastest_lap_table_columns = [
        {'name': 'Lap #', 'id': 'lap_number'},
        {'name': 'Full Name', 'id': 'full_name'},
        # Add more columns with logical names as needed
        {'name': 'Lap Time', 'id': 'lap_duration'},
        # Assuming segments were dropped as per the previous operation, omit them or adjust accordingly
    ]

    # Use these columns in the DataTable for laps_table
    laps_table = dash_table.DataTable(
        columns=lap_table_columns,  # Use the columns with user-friendly names
        data=laps_df.to_dict('records'),
        style_header={
            'backgroundColor': 'rgb(30, 30, 30)',
            'color': '#c9c9c9'
        },
        style_data={
            'backgroundColor': '#2b2d30',
            'color': '#c9c9c9'
        },
        id='laps-table'
    )

    # Use these columns in the DataTable for laps_table
    fastest_laps_table = dash_table.DataTable(
        columns=fastest_lap_table_columns,  # Use the columns with user-friendly names
        data=laps_df.to_dict('records'),
        style_header={
            'backgroundColor': 'rgb(30, 30, 30)',
            'color': '#c9c9c9'
        },
        style_data={
            'backgroundColor': '#2b2d30',
            'color': '#c9c9c9',
            # 'overflowY': 'scroll'
        },
        id='fastest-laps-table',
    )

    drivers_table = dash_table.DataTable(
        columns=drivers_columns,
        id='drivers-table',
        data=drivers_df.to_dict('records'),
        style_cell={'textAlign': 'left', 'border': '2px solid #1e1f22'},
        style_cell_conditional=[
            {'if': {'column_id': 'headshot'}, 'textAlign': 'center'},
            {'if': {'column_id': 'driver_number'}, 'textAlign': 'center'},  # Center-align the headshot column
        ],
        style_header={
            'backgroundColor': 'rgb(30, 30, 30)',
            'color': '#c9c9c9'
        },
        style_data={
            'backgroundColor': '#2b2d30',
            'color': '#c9c9c9'
        },
        markdown_options={'html': True}  # Enable Markdown rendering for the headshot column
    )

    # Update the DataFrame for 'CHEQUERED' flags to include the HTML image tag
    chequered_img_tag = '<img src="/assets/chequered.png" style="width: 80px; max-width: 100%; height: 40px; max-height: 100%; display: block; margin: 0 auto;">'
    race_control_df['flag'] = race_control_df['flag'].apply(
        lambda x: chequered_img_tag if x is not None and x.upper() == "CHEQUERED" else x
    )

    # Ensure the columns reference the correct DataFrame
    columns = [
        {'name': i, 'id': i, 'presentation': 'markdown' if i == 'flag' else None}
        for i in race_control_df.columns if i != 'timestamp'
    ]
    # print(race_control_df['flag'])
    # DataTable setup, now correctly referencing the updated DataFrame
    # race_control_table = dash_table.DataTable(
    #     columns=columns,
    #     data=race_control_df.to_dict('records'),
    #     fixed_rows={'headers': True},
    #     style_table={'overflowX': 'auto', 'overflowY': 'auto', 'height': '400px'},
    #     sort_action='native',
    #     style_cell={'textAlign': 'left', 'border': '2px solid #1e1f22'},
    #     sort_by=[{'column_id': 'date_start', 'direction': 'desc'}],
    #     style_header={'backgroundColor': 'rgb(30, 30, 30)', 'color': '#c9c9c9'},
    #     style_data={'backgroundColor': '#2b2d30', 'color': '#c9c9c9'},
    #     id='race-control-table',
    #     style_data_conditional=[
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "YELLOW"'
    #             },
    #             'backgroundColor': 'yellow',
    #             'color': 'black'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "RED"'
    #             },
    #             'backgroundColor': 'red',
    #             'color': 'white'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "GREEN"'
    #             },
    #             'backgroundColor': 'green',
    #             'color': 'white'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "CHEQUERED"'
    #             },
    #             'backgroundColor': 'black',
    #             'color': 'white'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "BLACK AND WHITE"'
    #             },
    #             'backgroundColor': 'black',
    #             'color': 'white'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "CLEAR"'
    #             },
    #             'backgroundColor': 'green',  # Assuming 'clear' means a white or transparent background for visibility
    #             'color': 'white'
    #         },
    #         {
    #             'if': {
    #                 'column_id': 'flag',
    #                 'filter_query': '{flag} contains "BLUE"'
    #             },
    #             'backgroundColor': 'royalblue',
    #             'color': 'white'
    #         },
    #     ],
    #     markdown_options={"html": True},  # Enable HTML content within Markdown cells
    # )


    initial_laps_over_time_plots = plot_driver_laps_over_time(all_laps_df,drivers_df)
    laps_plot_placeholder = html.Div(id='laps-plot')

    gmt_clock = daq.LEDDisplay(
    id='gmt-clock',
    value="00:00:00",
    size=12,
    color="#E06160",
    label="GMT Time",
    labelPosition='bottom',
    backgroundColor="#2b2d30"
    )
    local_clock = daq.LEDDisplay(
    id='local-clock',
    value="00:00:00",
    size=12,
    color="#E06160",
    label="Local Time",
    labelPosition='bottom',
    backgroundColor="#2b2d30"
)
    user_clock = daq.LEDDisplay(
    id='user-clock',
    value="00:00:00",
    size=12,
    color="#E06160",
    label="User Time",
    labelPosition='bottom',
    backgroundColor="#2b2d30"
)

    print(session_name)
    return dbc.Container([
        html.H2(f"Session Details for {session_name} in {meeting_name}"),
        dcc.Link(dmc.Button(f'Home', variant="filled", color="blue"), href='/'),
        # session_details_table,  # Display the session details table
        dbc.Row([
            dbc.Col(gmt_clock, width='auto'),  # Half the width of the row
            dbc.Col(local_clock, width='auto'),  # Half the width of the row
            dbc.Col(user_clock, width='auto')  # Half the width of the row
        ], justify="start") , # Align to the left side of the screen
        html.Div([
            markers_div,
            dcc.Slider(
                id='time-slider',
                min=weather_df['timestamp'].min(),
                max=race_control_df['timestamp'].max(),
                value=race_control_df['timestamp'].max(),
                marks=slider_labels,  # Use the new labels
                step=None
            ),
            html.Button('Play', id='play-button'),
            html.Div(id='playback', style={'display': 'none'}, children='stop'),
        ], style={'margin-top': '30px', 'margin-bottom': '10px'}),  # Add vertical space
        dbc.Row([
            dbc.Col([
                dbc.Row([
                    html.H3(id='driver-name-display', style={'text-align': 'center'}),
                    dcc.Graph(figure=track_map,
                              config={'autosizable': True, 'responsive': True, 'displayModeBar': False}, id='live-map')
                ]),
                dbc.Row([
                    html.Div(id='telemetry-plots', children=[initial_telemetry_plots])
                ]),
                dbc.Row([
                    # html.H3('Driver Lap Distributions'),
                    # # dcc.Graph(figure=driver_position_plot),
                    dcc.Graph(figure=initial_laps_over_time_plots,
                              config={'displayModeBar': False, 'doubleClick': False}),
                    ])
            ], width=12, lg=5),
            # This section will take up the whole width on small screens and a third of the width on large screens
            dbc.Col([
                dbc.Row([
                    html.H3('Laps'),
                    dash_table.DataTable(
                        id='laps-table',
                        columns=lap_table_columns,
                        data=laps_df.to_dict('records'),
                        sort_action='native',
                        style_cell={
                            'textAlign': 'left',
                            'border': '2px solid #1e1f22',
                            'fontSize': '13px',
                            'padding': '5px',
                        },
                        style_table={
                            'overflowX': 'auto',
                            'maxHeight': None,
                        },
                        style_header={
                            'backgroundColor': 'rgb(30, 30, 30)',
                            'color': '#c9c9c9'
                        },
                        style_data={
                            'backgroundColor': '#2b2d30',
                            'color': '#c9c9c9'
                        },
                        row_selectable='single',
                    ),
                ]),
                dbc.Row([
                    html.H3('Stints'),
                    dcc.Graph(figure=stints_plot,
                              config={'displayModeBar': False, 'doubleClick': False}),
                ]),
                dbc.Row([
                    html.H3('Positions Over Time'),
                    dcc.Graph(figure=initial_positions_over_time_plot,
                              config={'displayModeBar': False, 'doubleClick': False}),
                ]),
                dbc.Row([
                    html.H3('Race Control Events'),  # Header for the race control events table
                    # race_control_table,
                    dash_table.DataTable(
                        columns=columns,
                        data=race_control_df.to_dict('records'),
                        fixed_rows={'headers': True},
                        style_table={'overflowX': 'auto', 'height': '800px'},
                        sort_action='native',
                        style_cell={
                            'textAlign': 'left',
                            'border': '2px solid #1e1f22',
                            'fontSize': '13px',
                            'padding': '5px',
                        },
                        sort_by=[{'column_id': 'date_start', 'direction': 'desc'}],
                        style_header={'backgroundColor': 'rgb(30, 30, 30)', 'color': '#c9c9c9'},
                        style_data={'backgroundColor': '#2b2d30', 'color': '#c9c9c9'},
                        id='race-control-table',
                        style_data_conditional=[
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "YELLOW"'
                                },
                                'backgroundColor': 'yellow',
                                'color': 'black',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "RED"'
                                },
                                'backgroundColor': 'red',
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "GREEN"'
                                },
                                'backgroundColor': 'green',
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "CHEQUERED"'
                                },
                                'backgroundColor': 'black',
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "BLACK AND WHITE"'
                                },
                                'backgroundColor': 'black',
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "CLEAR"'
                                },
                                'backgroundColor': 'green',
                                # Assuming 'clear' means a white or transparent background for visibility
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                            {
                                'if': {
                                    'column_id': 'flag',
                                    'filter_query': '{flag} contains "BLUE"'
                                },
                                'backgroundColor': 'royalblue',
                                'color': 'white',
                                'textAlign': 'left',
                                'border': '2px solid #1e1f22',
                                'fontSize': '13px',
                                'padding': '5px',
                            },
                        ],
                        markdown_options={"html": True},  # Enable HTML content within Markdown cells
                    ),
                ])
            ], width=12, lg=7)
            # This section will take up the whole width on small screens and a third of the width on large screens
        ]),
        html.Div([fastest_laps_table], style={'display': 'none'}, id='hidden-fastest-laps-table'),
        html.H3('Weather'),
        # weather_plots,
        html.Div(id='weather-plots', children=[initial_weather_plots]),



        # html.H3('Drivers'),
        # drivers_table,  # Display the drivers table
        dcc.Interval(
            id='interval-component',
            interval=1*5000,  # in milliseconds
            n_intervals=0
        ),
        dcc.Interval(
            id='interval-component-clock',
            interval=1 * 1000,  # in milliseconds
            n_intervals=0
        ),
        store_session_key,
        drivers_data_store,
        race_control_data_store,
        weather_data_store,
        positions_data_store,
        laps_data_store,
        telemetry_laps_store,
    ], fluid=True)


last_row_selected=None


@app.callback(
	[Output('telemetry-plots', 'children'),
	 Output('live-map', 'figure'),
	 Output('driver-name-display', 'children')],
	[Input('laps-table', 'selected_rows'),
	 Input('laps-table', 'data')],
	[State('session-key-store', 'data'),
	 State('telemetry-laps-store', 'data'),
	 State('session-details-store', 'data')]
)
def update_plots(selected_rows, data, session_key, telemetry_laps_data, session_details):
	global last_row_selected, pos, circuit_info, circuit

	if selected_rows and selected_rows != last_row_selected:
		last_row_selected = selected_rows
		telemetry_laps_df = pd.DataFrame(telemetry_laps_data)
		selected_session_df = pd.DataFrame(session_details)
		selected_row_data = pd.DataFrame(data[selected_rows[0]], index=[0])

		driver_number = selected_row_data['driver_number'].astype(int).iloc[0]
		driver_name = selected_row_data['full_name'].iloc[0]
		lap_number = selected_row_data['lap_number'].iloc[0]

		telemetry_laps_df['date_start'] = pd.to_timedelta(telemetry_laps_df['date_start'])
		telemetry_laps_df['lap_duration'] = pd.to_timedelta("00:" + telemetry_laps_df['lap_duration'])

		session_date = pd.to_datetime(selected_session_df['date_start'].iloc[0])
		reference_date = datetime.combine(session_date.date(), datetime.min.time())

		driver_lap_start_td = telemetry_laps_df[telemetry_laps_df['driver_number'] == driver_number]['date_start'].iloc[
			0]
		driver_lap_end_td = driver_lap_start_td + \
		                    telemetry_laps_df[telemetry_laps_df['driver_number'] == driver_number]['lap_duration'].iloc[
			                    0]

		driver_lap_start_datetime = reference_date + driver_lap_start_td
		driver_lap_end_datetime = reference_date + driver_lap_end_td

		driver_lap_start = driver_lap_start_datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]
		driver_lap_end = driver_lap_end_datetime.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]

		locations_response = requests.get(
			f'https://api.openf1.org/v1/location?session_key={session_key}&driver_number={driver_number}&date>={driver_lap_start}&date<={driver_lap_end}')
		car_data_response = requests.get(
			f'https://api.openf1.org/v1/car_data?driver_number={driver_number}&session_key={session_key}&date>={driver_lap_start}&date<={driver_lap_end}')

		locations_df = pd.DataFrame(locations_response.json())
		car_data_df = pd.DataFrame(car_data_response.json())

		for df in [locations_df, car_data_df]:
			df['date'] = pd.to_datetime(df['date'].apply(lambda x: x + ".000000" if len(x) == 19 else x))

		locations_df = pd.merge_asof(
			locations_df,
			car_data_df,
			on='date',
			tolerance=pd.Timedelta('500ms')
		)
		locations_df = locations_df.dropna(subset=['rpm'])

		track_rotations = [('Sakhir', 92.0), ('Jeddah', 104.0), ('Melbourne', 44.0), ('Baku', 357.0), ('Miami', 2.0),
		                   ('Monte Carlo', 62.0), ('Catalunya', 95.0), ('Montreal', 62.0), ('Silverstone', 92.0),
		                   ('Hungaroring', 40.0), ('Spa-Francorchamps', 91.0), ('Zandvoort', 0.0), ('Monza', 95.0),
		                   ('Singapore', 335.0), ('Suzuka', 49.0), ('Lusail', 61.0), ('Austin', 0.0),
		                   ('Mexico City', 36.0), ('Interlagos', 0.0), ('Las Vegas', 90.0),
		                   ('Yas Marina Circuit', 335.0)]

		track_angle = next((rotation for name, rotation in track_rotations if name == circuit), 0) / 180 * np.pi
		scale_factor = 1
		locations_df[['x', 'y']] = locations_df[['x', 'y']].apply(
			lambda row: pd.Series(rotate([row['x'], row['y']], angle=track_angle) * scale_factor), axis=1)

		latest_locations_df = interpolate_points(locations_df, 20)

		latest_locations_df['hover_text'] = (
				'Speed: ' + latest_locations_df['speed'].astype(str) +
				'<br>RPM: ' + latest_locations_df['rpm'].astype(str) +
				'<br>Throttle: ' + latest_locations_df['throttle'].astype(str) +
				'<br>Gear: ' + latest_locations_df['n_gear'].astype(str) +
				'<br>DRS: ' + latest_locations_df['drs'].astype(str) +
				'<br>Brake: ' + latest_locations_df['brake'].astype(str)
		)

		# Create a new figure for the live map
		new_track_map, _ = plot_live_map(pos, circuit_info, circuit, latest_locations_df)

		# Update telemetry plots
		telemetry_plots = plot_telemetry(circuit_info, latest_locations_df)
		display_text = f"Driver: {driver_name}, Lap: {lap_number}"

		return telemetry_plots, new_track_map, display_text
	else:
		return no_update, no_update, no_update


@profile
@app.callback(
    [
        Output('laps-table', 'data'),
        Output('fastest-laps-table', 'data'),
        Output('weather-plots', 'children'),
        Output('race-control-table', 'data')
    ],
    [
        Input('time-slider', 'value'),
        Input('interval-component', 'n_intervals')
    ],
    [
        State('session-key-store', 'data'),
        State('laps-store', 'data'),
        State('race-control-store', 'data'),
        State('weather-store', 'data')
    ]
)
def update_components(selected_timestamp, n_intervals, session_key, laps_data_store, race_control_data_store, weather_data_store):
    if session_key is None:
        raise dash.exceptions.PreventUpdate

    # print('last update timestamps last update timestamp dict')
    # print(last_update_timestamps)

    # Initialize variables to hold current data to prevent overwriting with empty data
    current_laps_data = laps_data_store.get('laps_data', []) if laps_data_store else []
    current_race_control_data = race_control_data_store if race_control_data_store else []
    current_weather_data = weather_data_store.get('weather_data', []) if weather_data_store else []
    slider_labels = weather_data_store.get('slider_labels', {}) if weather_data_store else {}

    # Convert stored data back to DataFrame for processing
    laps_df = pd.DataFrame(current_laps_data)
    race_control_df = pd.DataFrame(current_race_control_data)
    weather_df = pd.DataFrame(current_weather_data)

    # Check if live data update is requested
    if selected_timestamp >= weather_df['timestamp'].max() if not weather_df.empty else 0:
        # Fetch and process new data
        # print("update components timestamp 2")
        # print(last_update_timestamps)
        new_weather_data, _ = fetch_and_update_data('weather', session_key, last_update_timestamps)
        new_laps_data, _ = fetch_and_update_data('laps', session_key, last_update_timestamps)
        new_race_control_data, _ = fetch_and_update_data('race_control', session_key, last_update_timestamps)

        # Update only if new data is not empty
        weather_plots = generate_weather_plots(new_weather_data) if not new_weather_data.empty else generate_weather_plots(weather_df)
        laps_table_data = new_laps_data.to_dict('records') if not new_laps_data.empty else current_laps_data
        race_control_table_data = new_race_control_data.to_dict('records') if not new_race_control_data.empty else current_race_control_data

        # Handle fastest laps separately if new laps data was fetched
        fastest_laps_table_data = new_laps_data[new_laps_data['lap_duration'].notna()].to_dict('records') if not new_laps_data.empty else current_laps_data
    else:
        # Use existing data to update components
        weather_plots = generate_weather_plots(weather_df)
        laps_table_data = current_laps_data
        fastest_laps_table_data = [record for record in current_laps_data if 'lap_duration' in record and record['lap_duration'] is not None]
        race_control_table_data = current_race_control_data

    return laps_table_data, fastest_laps_table_data, weather_plots, race_control_table_data


def fetch_and_update_data(data_type, session_key, last_update_timestamps):
    # Example URL construction, this needs to be adjusted according to actual API requirements
    # print("fetch and update last update timestamps")
    # print(last_update_timestamps)
    processed_data = pd.DataFrame()
    url = f"https://api.openf1.org/v1/{data_type}?session_key={session_key}&date>={last_update_timestamps[data_type]}"
    response = fetch_data(url)  # Assume this fetches data from the API
    new_data = response.json()
    # print(new_data)

    # Depending on the type of data, call the appropriate processing function
    if new_data:
        if data_type == 'drivers':
            processed_data, _ = process_drivers_data(new_data)
        elif data_type == 'race_control':
            processed_data = process_race_control_data(new_data)
        elif data_type == 'weather':
            processed_data, _ = process_weather_data(new_data)
        elif data_type == 'positions':
            processed_data = process_positions_data(new_data)
        elif data_type == 'laps':
            processed_data, _ = process_laps_data(new_data)

        # Update only if new data was fetched
        if not processed_data.empty:
            # print("last update timestamps")
            # print(last_update_timestamps)
            last_update_timestamps[data_type] = pd.to_datetime(datetime.now()) # Update the timestamp to now

    else:
        print(f"No new data for {data_type}")

    return processed_data, last_update_timestamps



@app.callback(
    Output('time-slider', 'value'),
    [Input('interval-component', 'n_intervals'),
     Input('playback', 'children')],
    [State('time-slider', 'value'),
     State('time-slider', 'max')]
)
def update_slider(n, playback, current_value, max_value):
    if playback == 'play':
        return min(current_value + 1, max_value)
    return current_value


@app.callback(
    [Output('play-button', 'children'), Output('playback', 'children')],
    Input('play-button', 'n_clicks'),
    prevent_initial_call=True
)
def toggle_playback(n_clicks):
    if n_clicks is None:
        raise dash.exceptions.PreventUpdate
    else:
        # Get the current button label
        button_label = dash.callback_context.triggered[0]['value']
        # If the current label is 'Play', change it to 'Stop' and start the playback
        if button_label == 'Play':
            return 'Stop', 'play'
        # If the current label is 'Stop', change it to 'Play' and stop the playback
        else:
            return 'Play', 'stop'


@app.callback(
    Output('url', 'pathname'),
    [Input('selected-meeting-key', 'children'), Input('selected-session', 'children')],
    [State('url', 'pathname')]
)
def navigate_based_on_selection(meeting_key, session_name, current_pathname):
    if not meeting_key and not session_name:
        raise PreventUpdate

    new_path = '/'
    if meeting_key:
        new_path = f'/{meeting_key}'
        if session_name:
            session_name_formatted = session_name.replace(' ', '_')
            new_path += f'/{session_name_formatted}'

    if new_path == current_pathname:
        raise PreventUpdate

    return new_path

@app.callback(Output('page-content', 'children'), [Input('url', 'pathname')])
def display_page(pathname):
    if pathname == '/' or pathname is None:
        return home_layout
    elif '/' in pathname:
        parts = [unquote(part) for part in pathname.split('/')]
        if len(parts) >= 3:
            meeting_key = parts[1]
            session_name = parts[2].replace('_', ' ')
            return generate_session_details_layout(meeting_key, session_name)
        else:
            return 'Error: Invalid session details URL.'
    else:
        return '404 - Page not found'


def convert_time_str_to_seconds(time_str):
    """Converts a time string in the format 'minutes:seconds.milliseconds' to total seconds."""
    if pd.isnull(time_str):
        return None
    minutes, seconds = time_str.split(':')
    total_seconds = float(minutes) * 60 + float(seconds)
    return total_seconds

def plot_driver_laps_over_time(all_laps_df, drivers_df):

    # Merge laps_df with drivers_df to get the team colors
    merged_df = pd.merge(all_laps_df, drivers_df[['full_name', 'team_colour']], on='full_name', how='left')
    # print(merged_df.columns)
    # print(merged_df['is_pit_out_lap'].dtypes)
    merged_df = merged_df.loc[merged_df['is_pit_out_lap'] != True]
    # Calculate median lap times for each driver
    median_lap_times = merged_df.groupby('full_name')['lap_duration'].median()

    # Identify drivers with median lap time > 0 and sort in ascending order
    drivers_with_data = median_lap_times[median_lap_times > 0].sort_values(ascending=True)

    # Identify drivers with median lap time == 0 or no lap times
    drivers_without_data = median_lap_times[median_lap_times <= 0]

    # Combine the drivers, prioritizing those with data
    sorted_drivers = pd.concat([drivers_with_data, drivers_without_data]).index.tolist()

    # Initialize a plotly graph object figure with dynamic height to accommodate all violins
    fig_height = 100 + len(sorted_drivers) * 40  # 40 pixels per violin, plus some padding
    fig = go.Figure(layout={'height': fig_height})

    # Determine the x-axis range to shorten the tail of the distribution
    all_laps = merged_df['lap_duration'].dropna()
    # print("all laps columns:", all_laps_df.columns)
    q1, q3 = np.percentile(all_laps, [25, 75])
    iqr = q3 - q1
    upper_limit = q3 + 1.5 * iqr  # Adjust this factor to control the tail shortening
    min_lap_times = merged_df.groupby('full_name')['lap_duration'].min()

    # Add a violin plot for each driver's lap times
    for i, driver in enumerate(sorted_drivers):
        reversed_index = len(sorted_drivers) - 1 - i
        driver_df = merged_df[merged_df['full_name'] == driver]
        team_color = driver_df['team_colour'].iloc[0]
        driver_laps = driver_df['lap_duration'].dropna()


        # Y position for each violin is offset to prevent overlap
        y_position = np.full(len(driver_laps), i)

        fig.add_trace(go.Violin(
            y=np.full(len(driver_laps), reversed_index),
            x=driver_laps,
            name=driver,
            line_color=team_color,
            side='positive',
            width=3,  # Adjust the width to your preference
            points=False,
            orientation='h',
            meanline_visible=True,

        ))
        fig.update_traces(orientation='h')
        # Add a scatter plot for each driver's minimum lap time
        for i, driver in enumerate(sorted_drivers):
            reversed_index = len(sorted_drivers) - 1 - i
            min_lap_time = min_lap_times[driver]
            team_color = drivers_df[drivers_df['full_name'] == driver]['team_colour'].iloc[0]  # Get the team color for the driver
            # print(team_color)
            fig.add_trace(go.Scatter(
                x=[min_lap_time],
                y=[reversed_index],
                mode='markers',
                name=driver,
                fillcolor=team_color,
                marker=dict(
                    size=5,  # Change the size to your preference
                    line=None,
                ),
                showlegend=False
            ))

    # Update the layout of the figure, including x-axis range to shorten the tail

    fig.update_layout(
        dragmode=False,
        xaxis=dict(
            showgrid=False,
            zeroline=False,
            title='Lap Time (seconds)',
            range=[q1 - 1.75 * iqr, q3 + 2.25 * iqr]
        ),
        yaxis=dict(
            showgrid=False,
            showline=False,
            zeroline=False,
            showticklabels=True,
            tickmode='array',
            tickvals=list(range(len(sorted_drivers))),
            ticktext=sorted_drivers[::-1],
            range=[-1, len(sorted_drivers)+1]  # Set the y-axis range
        ),
        autosize=True,
        showlegend=False,
        margin=dict(l=50, r=0, t=25, b=0),  # Adjust margins to ensure labels fit
        paper_bgcolor="#2b2d30",
        plot_bgcolor='#2b2d30',
        font=dict(color="#c9c9c9"),
    )

    return fig

def plot_driver_positions_over_time(positions_df, all_laps_df):
    # Convert 'date' to datetime format for proper plotting
    positions_df['date'] = pd.to_datetime(positions_df['date'], format='ISO8601')
    # print(all_laps_df['date_start'])
    # all_laps_df = all_laps_df.dropna(subset=['date_start'])
    # print(all_laps_df.columns)
    # print(all_laps_df['date_start'].iloc[0])
    # all_laps_df['date_start'] = pd.to_datetime(all_laps_df['date_start'], format='ISO8601')
    # # Merge the DataFrames on the 'date' column
    # all_laps_df = all_laps_df.sort_values(by='date_start')
    # merged_df = pd.merge_asof(positions_df, all_laps_df, left_on='date', right_on='date_start', by='driver_number',
    #                           direction='backward')
    # print(merged_df)
    # Drop the first row if necessary
    positions_df = positions_df.groupby('driver_number').apply(lambda x: x.iloc[1:]).reset_index(drop=True)

    # Initialize a plotly graph object figure
    fig = go.Figure()

    # Get a list of unique drivers
    drivers = positions_df['driver_number'].unique()

    # Loop through each driver and add a trace for their positions over time
    for driver in drivers:
        driver_df = positions_df[positions_df['driver_number'] == driver]
        # Ensure the driver's data is sorted by date
        driver_df = driver_df.sort_values(by='date')
        fig.add_trace(
            go.Scatter(x=driver_df['date'], y=driver_df['position'], mode='lines+markers', name=f'Driver {driver}'))

    # Update the layout of the figure
    fig.update_layout(
        # title='Driver Positions Over Time',
        xaxis_title='Time',
        yaxis_title='Position',
        xaxis_zeroline=False,
        yaxis_zeroline=False,
        legend_title='Driver Number',
        paper_bgcolor="#2b2d30",  # Sets the background color for the entire figure
        plot_bgcolor="#2b2d30",  # Sets the plot area background color
        font=dict(color="#c9c9c9"),  # Adjusts the font color to improve contrast
        xaxis=dict(showline=True, showgrid=True, gridcolor='#444444', zeroline=False, linewidth=2, ticks='outside',
                   showspikes=True,
                   spikemode='across',
                   spikesnap='cursor',
                   spikedash='solid',
                   spikethickness=2,
                   ),
        yaxis=dict(autorange="reversed", showgrid=True, gridcolor='#444444', zeroline=False, showline=False, showticklabels=True),
        autosize=True,
        showlegend=True,
        margin=dict(l=0, r=0, t=25, b=0),  # Adjust margins to ensure labels fit
    )

    # Reverse the y-axis to show the leading position at the top
    fig.update_yaxes(autorange="reversed")

    return fig


def plot_driver_stints(stints_df, pits_df):
    # Convert 'lap_start' and 'lap_end' to ensure they are integers
    stints_df['lap_start'] = stints_df['lap_start'].astype(int)
    stints_df['lap_end'] = stints_df['lap_end'].astype(int)

    # Convert 'driver_number' to int for consistency
    stints_df['driver_number'] = stints_df['driver_number'].astype(int)
    pits_df['driver_number'] = pits_df['driver_number'].astype(int)

    # Set up color mapping for tire compounds
    compound_colors = {
        "SOFT": "#fb3344",
        "MEDIUM": "#fde53b",
        "HARD": "#f9faf6"
    }

    # Create the figure
    fig = go.Figure()

    # Get a list of unique drivers
    drivers = stints_df['driver_number'].unique()

    for driver in drivers:
        driver_df = stints_df[stints_df['driver_number'] == driver]
        pit_stops_driver_df = pits_df[pits_df['driver_number'] == driver]

        for stint in driver_df.itertuples():
            color = compound_colors.get(stint.compound, "grey")  # Fallback color

            # Adding each stint as a separate trace
            fig.add_trace(go.Scatter(
                x=[stint.lap_start, stint.lap_end],
                y=[driver, driver],
                mode="lines+markers",
                name=f"Driver {driver}, Stint {stint.stint_number}",
                line=dict(color=color, width=4),
                marker=dict(color=color, size=12),
            ))

        for pit_stop in pit_stops_driver_df.itertuples():
            # Adding each pit stop as a separate trace
            fig.add_trace(go.Scatter(
                x=[pit_stop.lap_number, pit_stop.lap_number],
                y=[driver, driver],
                mode="markers",
                name=f"Driver {driver}, Pit Stop {pit_stop.Index}",
                marker=dict(color='white', size=12, symbol='x'),
            ))

    # Update the layout of the figure
    fig.update_layout(
        xaxis_title='Lap',
        yaxis_title='Driver Number',
        yaxis=dict(type='category', categoryorder='category ascending', autorange="reversed"),
        xaxis=dict(showline=True, showgrid=True, gridcolor='#444444', zeroline=False, linewidth=2, ticks='outside',
                   showspikes=True,
                   spikemode='across',
                   spikesnap='cursor',
                   spikedash='solid',
                   spikethickness=2),
        paper_bgcolor="#2b2d30",
        plot_bgcolor="#2b2d30",
        font=dict(color="#c9c9c9"),
        showlegend=False,
        autosize=True,
        margin=dict(l=0, r=0, t=25, b=0),
    )

    return fig



def generate_weather_plots(weather_df, title_font_size=11, axis_title_font_size=11, axis_tick_font_size=11,
                           data_point_size=1, global_margin='0px', total_height=500):
    df = weather_df

    df['date'] = pd.to_datetime(df['date'], format='ISO8601')

    # Convert wind speed from m/s to knots
    df.loc[:, 'wind_speed_knots'] = df['wind_speed'] * 1.94384

    # Convert temperatures to Fahrenheit
    df['air_temperature_f'] = df['air_temperature'] * 9/5 + 32
    df['track_temperature_f'] = df['track_temperature'] * 9/5 + 32

    # Define colors for the lines in the order: Plotly's default blue, red, green
    colors = ['#636efa', '#ef553b', '#00cc96']

    # Adjust the height for each stack based on the number of plots
    temp_stack_plots = 2
    prh_stack_plots = 3
    wind_stack_plots = 2

    # Adjust the height for each stack based on the number of plots
    wind_stack_height = total_height  # Total height allocated for wind plots

    # Calculate individual plot heights
    wind_direction_plot_height = 2 * wind_stack_height / 3  # Two-thirds for wind direction
    wind_speed_plot_height = wind_stack_height / 3  # One-third for wind speed

    # Calculate individual plot heights
    temp_plot_height = total_height / temp_stack_plots
    prh_plot_height = total_height / prh_stack_plots
    wind_plot_height = total_height / wind_stack_plots

    # Define plot layout arguments
    def plot_layout_args(height):
        return {
            'title_font': {'size': title_font_size},
            'height': height,
            'margin': {'l': 0, 'r': 0, 't': 30, 'b': 30},
            'legend': {'orientation': 'h', 'x': 0.5, 'y': 1.2, 'xanchor': 'center', 'yanchor': 'bottom'},
            'dragmode': False,
            'hovermode': 'x'
        }

    # Helper function to create a figure
    def create_figure(x, y, name, color, title, yaxis_title, height):
        fig = go.Figure()
        if name == 'Wind Direction (°)':
            fig.add_trace(go.Scatterpolar(
                r=y,
                theta=x,
                mode='markers',
                name=name,
                marker=dict(color=color, size=6),
                line=dict(color=color),
            ))

            fig.update_layout(
                **plot_layout_args(height),
                title=title,
                polar=dict(
                    bgcolor="#2b2d30",  # Sets the polar plot background color
                    radialaxis=dict(
                        nticks=5,  # Adjust this value to change the number of radial ticks (circles)
                        color="#c9c9c9",  # Sets the color of the radial axis text
                    ),
                    angularaxis=dict(
                        rotation=90,  # Starts the plot at 12 o'clock
                        direction="clockwise"  # Sets the direction of theta increase to clockwise
                    ),
                ),
                paper_bgcolor="#2b2d30",  # Sets the background color for the entire figure
                plot_bgcolor="#2b2d30",  # Sets the plot area background color
                font=dict(color="#c9c9c9")  # Adjusts the font color to improve contrast
            )

        else:
            fig = go.Figure(data=[
                go.Scatter(x=x, y=y, name=name, mode='lines+markers',
                           marker=dict(size=data_point_size), line=dict(color=color,shape='spline'))
            ])
            fig.update_layout(**plot_layout_args(height), title=title, yaxis_title=yaxis_title,
                              paper_bgcolor="#2b2d30",  # Sets the background color for the entire figure
                              plot_bgcolor="#2b2d30",  # Sets the plot area background color
                              font=dict(color="#c9c9c9"), # Adjusts the font color to improve contrast
                              xaxis_zeroline=False,  # Remove the x-axis zero line
                              yaxis_zeroline=False,
                              xaxis=dict(
                                  fixedrange=True,
                                  showgrid=True,  # Ensure gridlines are shown
                                  gridcolor='#444444',  # Dark grey gridlines
                                  showspikes=True,
                                  spikemode='across',
                                  spikesnap='cursor',
                                  spikedash='solid',
                                  spikethickness=2,
                              ),
                              yaxis=dict(
                                  fixedrange=True,
                                  showgrid=True,
                                  # range=[0, max(y)] if name == 'Rainfall (mm)' else None,
                                  gridcolor='#444444',
                              ),

                              )
            fig.update_xaxes(tickformat='%H:%M')
            fig.update_xaxes(showline=False)

        fig.update_xaxes(title_font={'size': axis_title_font_size}, tickfont={'size': axis_tick_font_size})
        fig.update_yaxes(title_font={'size': axis_title_font_size}, tickfont={'size': axis_tick_font_size})
        return fig

    # Convert time to two digits format for wind direction plot
    df['time_digits'] = df['date'].dt.strftime('%H:%M')

    # Create figures
    fig_air_temp = create_figure(df['date'], df['air_temperature'], 'Air Temperature (°C)', colors[0],
                                 'Air Temperature', 'Temperature (°C)', temp_plot_height)
    fig_track_temp = create_figure(df['date'], df['track_temperature'], 'Track Temperature (°C)', colors[1],
                                   'Track Temperature', 'Temperature (°C)', temp_plot_height)

    fig_pressure = create_figure(df['date'], df['pressure'], 'Pressure (hPa)', colors[0], 'Pressure',
                                 'Pressure (hPa)', prh_plot_height)
    fig_rainfall = create_figure(df['date'], df['rainfall'], 'Rainfall (mm)', colors[1], 'Rainfall',
                                 'Rainfall (mm)', prh_plot_height)
    fig_humidity = create_figure(df['date'], df['humidity'], 'Humidity (%)', colors[2], 'Humidity',
                                 'Humidity (%)', prh_plot_height)
    fig_wind_speed = create_figure(df['date'], df['wind_speed_knots'], 'Wind Speed (kts)', colors[0],
                                   'Wind Speed Over Time', 'Wind Speed (kts)', wind_speed_plot_height)
    fig_wind_direction = create_figure(df['wind_direction'], df['time_digits'], 'Wind Direction (°)', colors[1],
                                       'Wind Direction Over Time', 'Time of Day', wind_direction_plot_height)

    # Arrange plots horizontally with dynamic height allocation
    return dbc.Container([
        dbc.Row([
            dbc.Col([
                dcc.Graph(figure=fig_air_temp, config={'displayModeBar': False}),
                dcc.Graph(figure=fig_track_temp, config={'displayModeBar': False})
            ], width=12, lg=4, style={'height': f'{total_height}px'}),
            # Full width on XS and SM screens, 1/3rd on LG and above
            dbc.Col([
                dcc.Graph(figure=fig_pressure, config={'displayModeBar': False}),
                dcc.Graph(figure=fig_rainfall, config={'displayModeBar': False}),
                dcc.Graph(figure=fig_humidity, config={'displayModeBar': False})
            ], width=12, lg=4, style={'height': f'{total_height}px'}),
            # Full width on XS and SM screens, 1/3rd on LG and above
            dbc.Col([
                dcc.Graph(figure=fig_wind_speed, config={'displayModeBar': False}),
                dcc.Graph(figure=fig_wind_direction, config={'displayModeBar': False})
            ], width=12, lg=4, style={'height': f'{total_height}px'})
            # Full width on XS and SM screens, 1/3rd on LG and above
        ], className="g-0"),  # Adjust as needed for your gutters/spacing
    ], fluid=True)  # Ensure 'global_margin' is defined or adjust as necessary




@app.callback(
    [Output('gmt-clock', 'value'),
     Output('local-clock', 'value'),
     Output('user-clock', 'value'),
     Output('session-details-store', 'data')],  # Add an Output for the session details store
    [Input('interval-component-clock', 'n_intervals')],
    [State('session-key-store', 'data'),
     State('session-details-store', 'data')]  # Add a State for the session details store
)
def update_clocks(n, session_key, session_details):
    # Update the GMT clock
    gmt_time = datetime.utcnow()
    gmt_clock_value = gmt_time.strftime('%H:%M:%S')  # Format the time as HH:MM:SS

    user_clock_value = datetime.now().strftime('%H:%M:%S')

    # Placeholder for local time text
    local_clock_value = '00:00:00'

    if session_key:
        if session_details is None:
            # Fetch session details
            session_response = requests.get(f'https://api.openf1.org/v1/sessions?session_key={session_key}')
            session_data = session_response.json()
            session_df = pd.DataFrame(session_data)
            session_details = session_df.to_dict('records')

        else:
            session_df = pd.DataFrame(session_details)

        # Extract GMT offset from session details
        gmt_offset_str = session_df['gmt_offset'].iloc[0]

        # Parse the offset string into hours, minutes, and seconds
        hours, minutes, seconds = map(int, gmt_offset_str.split(':'))

        # Convert GMT time to local time using the GMT offset
        local_time = gmt_time + timedelta(hours=hours, minutes=minutes, seconds=seconds)

        # Update local clock text
        local_clock_value = local_time.strftime('%H:%M:%S')

    return gmt_clock_value, local_clock_value, user_clock_value, session_details


def fetch_data(url):
    try:
        response = requests.get(url)
        # Check if the response was successful
        if response.status_code == 200:
            return response
        else:
            print(f"Error fetching data: Status code {response.status_code}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
        return None

app.layout = html.Div([
    dcc.Location(id='url', refresh=False),
    html.Div(id='page-content'),
    # Hidden divs for storing state
    html.Div(id='selected-meeting-key', style={'display': 'none'}),
    html.Div(id='selected-meeting-name', style={'display': 'none'}),
    html.Div(id='selected-session', style={'display': 'none'}),
    dcc.Store(id='session-key-store'),
    dcc.Store(id='drivers-store'),
    dcc.Store(id='laps-store'),
    dcc.Store(id='telemetry-laps-store'),
    dcc.Store(id='weather-store'),
    dcc.Store(id='positions-store'),
    dcc.Store(id='race-control-store'),
    dcc.Store(id='last-update-timestamps-store', data={
            'weather': None,
            'drivers': None,
            'laps': None,
            'race_control': None
        }),
    # Add a new dcc.Store component to your layout
    dcc.Store(id='session-details-store')
])

if __name__ == '__main__':
    app.run_server(debug=True, host='0.0.0.0', port=8050)
